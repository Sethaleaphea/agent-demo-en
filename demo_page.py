from openai import OpenAI
import os
import json
from langchain_core.messages import (
    HumanMessage,
    AIMessage,
)


from dotenv import load_dotenv
import os
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
base_url = os.getenv("OPENAI_BASE_URL")
client = OpenAI(api_key=api_key, base_url=base_url)

def get_chat_r1(query: str):
    while True:
        try:
            completion = client.chat.completions.create(
                model="deepseek-r1",
                messages=[
                    {'role': 'user', 'content': query}
                ]
            )
            break
        except Exception as e:
            st.warning("å‡ºé”™è¯¯äº†ï¼Œæ­£åœ¨é‡è¯•...")
    return completion.choices[0].message.content

def get_chat_openai(query: str):
    while True:
        try:
            completion = client.chat.completions.create(
                model="deepseek-v3",
                messages=[
                    {'role': 'user', 'content': query}
                ]
            )
            break
        except Exception as e:
            st.warning("å‡ºé”™è¯¯äº†ï¼Œæ­£åœ¨é‡è¯•...")
    return completion.choices[0].message.content

from trustrag.modules.retrieval.dense_retriever import DenseRetrieverConfig, DenseRetriever
from trustrag.modules.retrieval.embedding import FlagModelEmbedding


def RAG(query: str, retriever: DenseRetriever):
    step_back_prompt="""ä½ æ˜¯ä¸€ä½æ“…é•¿ä»å…·ä½“é—®é¢˜ä¸­æç‚¼å‡ºæ›´é€šç”¨é—®é¢˜çš„ä¸“å®¶ï¼Œè¯¥é€šç”¨é—®é¢˜èƒ½æ­ç¤ºå›ç­”å…·ä½“é—®é¢˜æ‰€éœ€çš„åŸºæœ¬åŸç†ã€‚
    ä½ å°†ä¼šæ”¶åˆ°å…³äºä¸“å‡æœ¬æ•™è‚²ä¸­å„ä¸ªå­¦ç§‘çš„é—®é¢˜ï¼Œé’ˆå¯¹ç”¨æˆ·æå‡ºçš„å…·ä½“é—®é¢˜ï¼Œè¯·ä½ æç‚¼å‡ºä¸€ä¸ªæ›´æŠ½è±¡ã€æ›´é€šç”¨çš„é—®é¢˜ï¼Œè¯¥é—®é¢˜æ˜¯å›ç­”åŸé—®é¢˜æ‰€å¿…é¡»è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚
    æ³¨æ„ï¼šå¦‚æœé‡åˆ°ä¸è®¤è¯†çš„å•è¯æˆ–ç¼©ç•¥è¯­ï¼Œè¯·ä¸è¦å°è¯•æ”¹å†™å®ƒä»¬ã€‚è¯·å°½é‡ç¼–å†™ç®€æ´çš„é—®é¢˜ã€‚
    <ç”¨æˆ·çš„å…·ä½“é—®é¢˜>""" + query
    # messages=[
    #     {"role": "system", "content": step_back_prompt},
    #     {'role': 'user', 'content': query}
    # ]
    with st.status("query_refined...", expanded=True) as status:
        # query_refined = chatLLM.invoke(messages).content
        query_refined = get_chat_openai(step_back_prompt)
        st.markdown(query_refined)
        status.update(
            label='query_refined', state="complete", expanded=False
        )
    
    with st.status("RAG...", expanded=True) as status:
        contents = retriever.retrieve(query=query_refined, top_k=3)
        st.markdown(contents)
        status.update(
            label="RAG", state="complete", expanded=False
        )
    
    contents = '\n'.join([content['text'] for content in contents])
    return contents

def QA_RAG(query: str, retriever: DenseRetriever):
    with st.status("QA_RAG...", expanded=True) as status:
        contents = retriever.retrieve(query=query, top_k=3)
        st.markdown(contents)
        status.update(
            label="QA_RAG", state="complete", expanded=False
        )
    
    contents = '\n'.join([content['text'] for content in contents])
    return contents

from typing import Annotated
from typing_extensions import TypedDict
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langgraph.graph import END, StateGraph, START
from langgraph.graph.message import add_messages

config = {"configurable": {"thread_id": "1"}}
configA = {"configurable": {"thread_id": "2"}}
configB = {"configurable": {"thread_id": "3"}}


# TODO ç»“åˆæ•™æå†…å®¹
# è·å–å­¦ç”Ÿç”»åƒ
def stu_img(history_msg: str, student_id: str):
    if student_id == "A":
        stu_img = "è¿™åå­¦ç”Ÿåœ¨æ³•å­¦åŸºç¡€è¿™é—¨è¯¾çš„å­¦ä¹ ååˆ†ä¼˜ç§€ï¼Œä»–åœ¨è¿™æ–¹é¢çš„çŸ¥è¯†æ°´å¹³å¾ˆé«˜ï¼Œå¯¹äºä»–çš„æé—®ï¼Œæ•™å¸ˆåªéœ€è¦ç¨åŠ ç‚¹æ‹¨ï¼Œç»™å‡ºä¸€ç‚¹å¯å‘å³å¯ï¼Œä»–å¯¹äºæ°‘æ³•ä¸­çš„æ¡ˆä¾‹åˆ†æè¿˜ä¸å¤ªç†Ÿç»ƒï¼Œéœ€è¦é€‚å½“ç»ƒä¹ ã€‚"
    elif student_id == "B":
        stu_img = "å­¦ç”Ÿåœ¨æ³•å­¦åŸºç¡€è¿™é—¨è¯¾çš„å­¦ä¹ æ¯”è¾ƒä¸€èˆ¬ï¼Œä»–å¯¹äºå®ªæ³•ã€åˆ‘æ³•ç›¸å…³çŸ¥è¯†ç‚¹å°šæœ‰ä¸æ˜ï¼Œä½†æ˜¯ä»–åœ¨è®¡ç®—æœºåŸºç¡€è¿™é—¨è¯¾è¡¨ç°ååˆ†ä¼˜ç§€ï¼Œå°¤å…¶æ˜¯æ•°æ®åº“åŸç†è¿™éƒ¨åˆ†ã€‚"
    else:
        # TODO æ›´æ–°å­¦ç”Ÿç”»åƒ
        query = '''ä½ æ˜¯ä¸€ä¸ªæ“…é•¿åˆ¤æ–­å­¦ç”ŸçŸ¥è¯†æ°´å¹³çš„æ•™å¸ˆï¼Œä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®å’Œå­¦ç”Ÿçš„å†å²è®°å½•æ¥åˆ¤æ–­å­¦ç”Ÿçš„çŸ¥è¯†æ°´å¹³ï¼Œå¹¶ä½¿ç”¨100å­—å·¦å³ç»™å‡ºä½ çš„çœ‹æ³•ã€‚\nå†å²å¯¹è¯è®°å½•ï¼š''' + history_msg
        stu_img = get_chat_openai(query)

    global stu_img_content
    stu_img_content = stu_img
    return stu_img

# check å­¦ç”Ÿå¯¹è¯
def check_msg(history_msg: str, student_msg: str):
    if history_msg == "":
        query = '''ä½ æ˜¯ä¸€ä¸ªæ•™å¸ˆï¼Œä½ æ­£åœ¨ä¸ä½ çš„å­¦ç”Ÿäº¤æµï¼Œä½ éœ€è¦åˆ¤æ–­å­¦ç”Ÿçš„è¯­å¥ä¸­æ˜¯å¦å­˜åœ¨é—®é¢˜ã€‚
ä½ éœ€è¦åˆ¤æ–­å­¦ç”Ÿæœ€æ–°ä¸€å¥è¯æ˜¯å¦å­˜åœ¨è¡¨è¾¾é”™è¯¯æˆ–å†…å®¹é”™è¯¯ã€‚
å¦‚æœä¸å­˜åœ¨é—®é¢˜ï¼Œä½ åªéœ€è¦å›å¤â€œæ— é—®é¢˜â€ã€‚
å¦‚æœå­˜åœ¨é—®é¢˜ï¼Œä½ éœ€è¦ç»™å‡ºåˆç†çš„å»ºè®®ã€‚
<æ³¨æ„äº‹é¡¹>
ä½ åªéœ€è¦åˆ¤æ–­å­¦ç”Ÿçš„è¯­å¥ä¸­æ˜¯å¦å­˜åœ¨é—®é¢˜ï¼Œä¸éœ€è¦å›ç­”å­¦ç”Ÿçš„é—®é¢˜ã€‚
å°½é‡è¾“å‡ºâ€œæ— é—®é¢˜â€ï¼Œé™¤éå­¦ç”Ÿçš„è¯æ˜æ˜¾ä¸äº‹å®ä¸ç¬¦ã€‚
<å­¦ç”Ÿæœ€æ–°ä¸€å¥è¯>
''' + student_msg
    else:
        query = '''ä½ æ˜¯ä¸€ä¸ªæ•™å¸ˆï¼Œä½ æ­£åœ¨ä¸ä½ çš„å­¦ç”Ÿäº¤æµï¼Œä½ éœ€è¦æ ¹æ®å’Œå­¦ç”Ÿçš„å†å²å¯¹è¯ï¼Œä»¥åŠå½“å‰å­¦ç”Ÿè¯­è¨€æ¥åˆ¤æ–­ï¼Œå­¦ç”Ÿçš„è¯­å¥ä¸­æ˜¯å¦å­˜åœ¨é—®é¢˜ã€‚
ä½ éœ€è¦åˆ¤æ–­å­¦ç”Ÿçš„æœ€æ–°ä¸€å¥è¯æ˜¯å¦ä¸ä¹‹å‰çš„å¯¹è¯å­˜åœ¨çŸ›ç›¾ï¼Œæˆ–æ˜¯å­¦ç”Ÿæœ€æ–°ä¸€å¥è¯æ˜¯å¦å­˜åœ¨çŸ¥è¯†ç‚¹ç†è§£æœ‰è¯¯ã€‚
å¦‚æœä¸å­˜åœ¨é—®é¢˜ï¼Œä½ åªéœ€è¦å›å¤â€œæ— é—®é¢˜â€ã€‚
å¦‚æœå­˜åœ¨é—®é¢˜ï¼Œä½ éœ€è¦ç»™å‡ºåˆç†çš„å»ºè®®ã€‚
<æ³¨æ„äº‹é¡¹>
ä½ åªéœ€è¦åˆ¤æ–­å­¦ç”Ÿçš„è¯­å¥ä¸­æ˜¯å¦å­˜åœ¨é—®é¢˜ï¼Œä¸éœ€è¦å›ç­”å­¦ç”Ÿçš„é—®é¢˜ã€‚
å°½é‡è¾“å‡ºâ€œæ— é—®é¢˜â€ï¼Œé™¤éå­¦ç”Ÿçš„è¯æ˜æ˜¾ä¸äº‹å®ä¸ç¬¦ï¼Œæˆ–å­˜åœ¨æ˜æ˜¾å‰åçŸ›ç›¾ã€‚
<å†å²å¯¹è¯è®°å½•>
''' + history_msg + '''
<å­¦ç”Ÿæœ€æ–°ä¸€å¥è¯>
''' + student_msg
    print(query)
    return get_chat_openai(query)

# é—®é¢˜æ”¹å†™agent
def question_rewrite(history_msg: str, student_msg: str):
    if history_msg == "":
        return student_msg
    query = '''ä½ æ˜¯ä¸€ä¸ªè¯­è¨€å­¦å®¶ï¼Œä½ éœ€è¦æ ¹æ®ä¸€æ®µå†å²å¯¹è¯è®°å½•å’Œå­¦ç”Ÿæœ€æ–°çš„ä¸€æ®µè¯ï¼Œæ¥æ”¹å†™å­¦ç”Ÿçš„æœ€æ–°æé—®ï¼Œç¡®ä¿æ”¹å†™å¾—åˆ°çš„è¯èƒ½è¡¨è¾¾å­¦ç”Ÿçš„æƒ³æ³•ï¼Œå¹¶ä¸”ç‹¬ç«‹äºå¯¹è¯è®°å½•ã€‚
<æ³¨æ„äº‹é¡¹>
ä½ åªéœ€è¦æ”¹å†™å­¦ç”Ÿçš„æé—®ï¼Œä¸éœ€è¦å›ç­”å­¦ç”Ÿçš„é—®é¢˜ã€‚
ä½ éœ€è¦å°½é‡ä¿ç•™å­¦ç”Ÿæé—®ä¸­çš„ä¿¡æ¯ï¼Œå¹¶ä¸”å¢åŠ ä¸€äº›å¿…è¦çš„å¯¹è¯è®°å½•ä¸­æåˆ°çš„ä¿¡æ¯ç¡®ä¿æ”¹å†™åçš„æé—®èƒ½å¤Ÿè¡¨è¾¾å­¦ç”Ÿçš„æ„å›¾ã€‚
ä½ éœ€è¦ç¡®ä¿æ²¡æœ‰å¯¹è¯è®°å½•çš„æƒ…å†µä¸‹ï¼Œä½ çš„æ”¹å†™èƒ½å¤Ÿè®©äººæ˜ç™½å­¦ç”Ÿçš„æƒ³æ³•ã€‚
ä½ åªéœ€è¦è¾“å‡ºæ”¹å†™åçš„é—®é¢˜ï¼Œè€Œä¸éœ€è¦è¾“å‡ºä½ çš„åˆ†æè¿‡ç¨‹ã€‚
<å†å²å¯¹è¯è®°å½•>
''' + history_msg + '''
<å­¦ç”Ÿæœ€æ–°ä¸€å¥è¯>
''' + student_msg
    return get_chat_openai(query)

def worng_question_rewrite(history_msg: str, student_msg: str, wrong_msg: str):
    # worng_msg = "ä¿®æ”¹æ„è§"
    # æ¨æµ‹ç”¨æˆ·æ„å›¾ï¼Œè§£ç­” è¿”å›
    query ='''ä½ æ˜¯ä¸€ä¸ªè¯­è¨€ä¸“å®¶ï¼Œä½ éœ€è¦æ ¹æ®å­¦ç”Ÿçš„æœ€æ–°ä¸€å¥è¯å’Œå†å²å¯¹è¯è®°å½•ï¼Œä»¥åŠåŒäº‹ç»™ä½ çš„ä¿®æ”¹æ„è§ï¼Œæ¥æŒ‡å‡ºå­¦ç”Ÿæé—®ä¸­çš„é—®é¢˜ï¼Œå¹¶ç»™å‡ºåˆç†çš„ä¿®æ”¹æ„è§ã€‚
å‘ä»–è§£é‡Šä¸ºä»€ä¹ˆä»–çš„é”™è¯¯ç†è§£ï¼Œä»¥æé«˜ä»–çš„çŸ¥è¯†æ°´å¹³ã€‚
<å†å²å¯¹è¯è®°å½•>
''' + history_msg + '''
<å­¦ç”Ÿæœ€æ–°ä¸€å¥è¯>
''' + student_msg + '''
<ä¿®æ”¹æ„è§>
''' + wrong_msg
    return get_chat_openai(query)
# è·¯ç”± æ„å›¾è¯†åˆ«
def route_intent(student_msg: str):
    query = '''ä½ æ˜¯ä¸€ä¸ªæ•™å¸ˆï¼Œä½ æ­£åœ¨ä¸ä½ çš„å­¦ç”Ÿäº¤æµï¼Œä½ éœ€è¦æ ¹æ®å½“å‰å­¦ç”Ÿæœ€æ–°ä¸€å¥è¯æŒ‰ä¸‹é¢çš„æµç¨‹åˆ¤æ–­å­¦ç”Ÿå½“å‰æ„å›¾ã€‚
1. åˆ¤æ–­å­¦ç”Ÿæ˜¯å¦åœ¨å’Œä½ è®¨è®ºæœ‰å…³å­¦ç§‘çš„é—®é¢˜æˆ–æ˜¯æé—®ï¼Œå¦‚æœä¸æ˜¯ï¼Œè¾“å‡ºâ€œæ—¥å¸¸å¯¹è¯â€ã€‚
2. åˆ¤æ–­å­¦ç”Ÿçš„ç–‘é—®æ˜¯å¦ä»…å±€é™äºçŸ¥è¯†æ¦‚å¿µä¸æ˜ï¼Œä¹Ÿå°±æ˜¯è¯´é¢˜ç›®çš„éš¾ç‚¹åœ¨äºçŸ¥è¯†æ¦‚å¿µçš„è®°å¿†å’Œç†è§£è€Œéåº”ç”¨ï¼Œå¦‚æœæ˜¯ï¼Œè¾“å‡ºâ€œæ¦‚å¿µæ€§é—®é¢˜â€ã€‚
3. ä»¥ä¸Šä¸¤ç§å‡ä¸å±äºè¾“å‡ºâ€œä¹ é¢˜è§£ç­”â€ã€‚
å­¦ç”Ÿæœ€æ–°ä¸€å¥è¯ï¼š''' + student_msg
    return get_chat_openai(query)

# ä¹ é¢˜è§£ç­”
def answer(student_msg: str, stu_img_content: str):
    # åˆ†æ­¥éª¤ç»™å‡ºè§£ç­” ä»¥ä¾¿å­¦ç”Ÿæé—®å’Œç†è§£
    rag_prompt = '''ä½ æ˜¯ä¸€ä¸ªæ•™å¸ˆï¼Œä½ æ­£åœ¨ä¸ä½ çš„å­¦ç”Ÿäº¤æµï¼Œä½ éœ€è¦å‘å­¦ç”Ÿè§£ç­”ä»–ä¸æ‡‚çš„ä¹ é¢˜ï¼Œè¯·ç»“åˆå¯å‚è€ƒçš„ä¸Šä¸‹æ–‡å†…å®¹ä»¥åŠè¯¦ç»†é—®é¢˜åŠè§£æä¸ºå­¦ç”Ÿè§£ç­”ã€‚
åŒæ—¶ï¼Œå­¦ç”Ÿç”»åƒåæ˜ äº†è¯¥å­¦ç”Ÿçš„çŸ¥è¯†æ°´å¹³ï¼Œè¯·æ ¹æ®ä¸‹é¢å­¦ç”Ÿç”»åƒä¸­åæ˜ å‡ºçš„çŸ¥è¯†æ°´å¹³ï¼Œä¸ºè¯¥å­¦ç”Ÿæä¾›ä¸ªæ€§åŒ–ã€åˆ†å±‚æ¬¡çš„è®²è§£ï¼Œè¦æ±‚é‡èº«å®šåˆ¶ï¼šå›ç­”æ—¶è¯·ç»“åˆå­¦ç”Ÿçš„çŸ¥è¯†æ°´å¹³ï¼Œé‡‡ç”¨é€‚åˆçš„æœ¯è¯­å’Œè§£é‡Šæ·±åº¦ã€‚
<æ³¨æ„äº‹é¡¹>
å¯¹äºä¼˜ç§€çš„å­¦ç”Ÿï¼Œä½ åªéœ€è¦ç»™å‡ºä¸€ç‚¹å¯å‘å³å¯ã€‚
å¯¹äºæ™®é€šå­¦ç”Ÿï¼Œä½ éœ€è¦ç»™å‡ºè¯¦ç»†çš„æ€è€ƒæ­¥éª¤ï¼Œä»¥ä¾¿å­¦ç”Ÿèƒ½å¤Ÿç†è§£ã€‚
<å­¦ç”Ÿçš„é—®é¢˜>
{question}
<å­¦ç”Ÿç”»åƒ>
{stu_img}
<ç›¸ä¼¼é¢˜ç›®>
    Â·Â·Â·
    {qa_contents}
    Â·Â·Â·
<å¯å‚è€ƒçš„ä¸Šä¸‹æ–‡>
    Â·Â·Â·
    {context}
    Â·Â·Â·"""
'''
    contents = RAG(student_msg, retriever)
    qa_contents = QA_RAG(user_message, qa_retriever)
    prompt = rag_prompt.format(question=student_msg, stu_img=stu_img_content,context=contents, qa_contents=qa_contents)
    
    return get_chat_r1(prompt)

# æ¦‚å¿µæ€§é—®é¢˜å›ç­”
def concept_answer(student_msg: str, stu_img_content: str):
    rag_prompt = '''ä½ æ˜¯ä¸€ä¸ªæ•™å¸ˆï¼Œä½ æ­£åœ¨ä¸ä½ çš„å­¦ç”Ÿäº¤æµï¼Œä½ éœ€è¦å‘å­¦ç”Ÿè§£ç­”ä»–ä¸æ‡‚çš„æ¦‚å¿µæ€§é—®é¢˜ã€‚è¯·ç»“åˆå‚è€ƒçš„ä¸Šä¸‹æ–‡å†…å®¹å›ç­”ç”¨æˆ·ä¸æ‡‚çš„æ¦‚å¿µæ€§é—®é¢˜ï¼Œå¹¶ä¸”ç»“åˆç›¸ä¼¼é—®é¢˜ï¼Œç»™å­¦ç”Ÿæ¨èé¢˜ç›®ã€‚
åŒæ—¶ï¼Œå­¦ç”Ÿç”»åƒåæ˜ äº†è¯¥å­¦ç”Ÿçš„çŸ¥è¯†æ°´å¹³ï¼Œè¯·æ ¹æ®ä¸‹é¢å­¦ç”Ÿç”»åƒä¸­åæ˜ å‡ºçš„çŸ¥è¯†æ°´å¹³ï¼Œä¸ºè¯¥å­¦ç”Ÿæä¾›ä¸ªæ€§åŒ–ã€åˆ†å±‚æ¬¡çš„è®²è§£ï¼Œè¦æ±‚é‡èº«å®šåˆ¶ï¼šå›ç­”æ—¶è¯·ç»“åˆå­¦ç”Ÿçš„çŸ¥è¯†æ°´å¹³ï¼Œé‡‡ç”¨é€‚åˆçš„æœ¯è¯­å’Œè§£é‡Šæ·±åº¦ã€‚
<ä»»åŠ¡æµç¨‹>
é¦–å…ˆï¼Œéœ€è¦æå–å‡ºå­¦ç”Ÿé—®é¢˜ä¸­çš„å…³é”®æ¦‚å¿µï¼Œç„¶åç»“åˆå¯å‚è€ƒçš„ä¸Šä¸‹æ–‡ï¼Œæ ¹æ®å­¦ç”Ÿç”»åƒç»™å‡ºä¸ªæ€§åŒ–çš„æ¦‚å¿µï¼Œå¹¶ä¸”ç»™å‡ºæœ€ç»ˆçš„ç­”æ¡ˆï¼Œæ³¨æ„è¿™ä¸€æ­¥å¿…é¡»ç»“åˆå­¦ç”ŸçŸ¥è¯†æ°´å¹³ï¼
å…¶æ¬¡ï¼Œä½ éœ€è¦ä»<ç›¸ä¼¼ä¹ é¢˜>ä¸­é€‰æ‹©æœ€ç¬¦åˆä¸»é¢˜çš„å®Œæ•´é¢˜ç›®ï¼Œæ¨èç»™å­¦ç”Ÿã€‚
æœ€åï¼Œä½ éœ€è¦å…³è”ä½ æ¨èçš„é¢˜ç›®è¿›ä¸€æ­¥è§£é‡Šè¯¥æ¦‚å¿µã€‚
<æ³¨æ„äº‹é¡¹> 
ä»»åŠ¡çš„å…¨è¿‡ç¨‹éƒ½éœ€è¦è€ƒè™‘å­¦ç”Ÿç”»åƒã€‚
å¦‚æœè¯¥å­¦ç”Ÿåœ¨é—®é¢˜çš„æ‰€å±ç§‘ç›®è¡¨ç°ä¼˜ç§€ï¼Œä½ åªéœ€è¦ç»™å‡ºä¸€ç‚¹å¯å‘å³å¯ï¼Œå¯¹äºå…¶ä»–çš„æ™®é€šå­¦ç”Ÿï¼Œä½ éœ€è¦ç»™å‡ºè¯¦ç»†çš„è§£ç­”ã€‚
ä½ éœ€è¦ç¡®ä¿ä½ ç»™å‡ºçš„é¢˜ç›®æ˜¯å®Œæ•´çš„ï¼Œä¾‹å¦‚ï¼Œé€‰æ‹©é¢˜åº”è¯¥å…·æœ‰é¢˜å¹²å’Œé€‰é¡¹ä»¥åŠç­”æ¡ˆè§£æï¼
ç»™å‡ºä¸å®Œæ•´çš„é¢˜ç›®ä¼šå½±å“å­¦ç”Ÿçš„å­¦ä¹ ï¼Œä½ åº”è¯¥é¿å…è¿™ä¸€ç‚¹ï¼
å¦‚æœä½ å‡†å¤‡æ¨èçš„é¢˜ç›®ä¸å­¦ç”Ÿçš„æé—®å®Œå…¨ä¸€è‡´ï¼Œåˆ‡è®°ä¸è¦æ¨èå’Œå­¦ç”Ÿæé—®ä¸€æ ·çš„é¢˜ç›®ï¼
<å­¦ç”Ÿçš„é—®é¢˜>
{question}
<å­¦ç”Ÿç”»åƒ>
{stu_img}
<ç›¸ä¼¼é¢˜ç›®>
    Â·Â·Â·
    {qa_contents}
    Â·Â·Â·
<å¯å‚è€ƒçš„ä¸Šä¸‹æ–‡>
    Â·Â·Â·
    {context}
    Â·Â·Â·'''
    contents = RAG(student_msg, retriever)
    qa_contents = QA_RAG(student_msg, qa_retriever)
    prompt = rag_prompt.format(question=student_msg, stu_img=stu_img_content,context=contents, qa_contents=qa_contents)
    return get_chat_r1(prompt)

# ç›¸ä¼¼é¢˜ç›®æ¨è
# def qa_recommend(llm, student_msg: str):
#     qa_contents = QA_RAG(user_message, qa_retriever)
#     messages = [
#         SystemMessage('''ä½ æ˜¯ä¸€ä¸ªä¼˜ç§€çš„æ•™å¸ˆï¼Œä½ æ­£åœ¨ä¸ä½ çš„å­¦ç”Ÿäº¤æµï¼Œä½ çš„ä»»åŠ¡æ˜¯ä¸ºå­¦ç”Ÿæ¨èå’Œä»–æå‡ºçš„é—®é¢˜ç›¸ä¼¼çš„ä¹ é¢˜ã€‚
#                       ä½ éœ€è¦æ ¹æ®ä»–çš„æœ€æ–°æé—®ï¼Œä»ç›¸ä¼¼ä¹ é¢˜ä¸­é€‰æ‹©æœ€ç±»ä¼¼çš„é¢˜ç›®ï¼Œå¹¶ä¸”æ¨èç»™ä»–ã€‚
#                       <æ³¨æ„äº‹é¡¹>
#                       ä½ åªéœ€è¦æ¨èå’Œå­¦ç”Ÿæé—®ç›¸ä¼¼çš„ä¹ é¢˜ï¼Œä¸éœ€è¦å›ç­”å­¦ç”Ÿçš„é—®é¢˜ã€‚
#                       ä½ åªéœ€è¦æ¨èæœ€ç›¸ä¼¼çš„1-2é“é¢˜ç›®å³å¯ã€‚
#                       <å­¦ç”Ÿæœ€æ–°ä¸€å¥è¯>ï¼š''' + student_msg + '''\nç›¸ä¼¼ä¹ é¢˜ï¼š''' + qa_contents),
#     ]
#     return llm.invoke(messages).content
# æ—¥å¸¸å¯¹è¯ å¼•å¯¼å­¦ç”Ÿæé—®
def daily_conversation(student_msg: str, stu_img_content: str):
    query = '''ä½ æ˜¯ä¸€ä¸ªä¼˜ç§€çš„æ•™å¸ˆï¼Œä½ æ­£åœ¨ä¸ä½ çš„å­¦ç”Ÿäº¤æµï¼Œä½ çš„ä»»åŠ¡æ˜¯å¯¹å­¦ç”Ÿçš„æœ€æ–°ä¸€å¥è¯è¿›è¡Œå›åº”ï¼ŒåŒæ—¶æ ¹æ®å­¦ç”Ÿçš„å­¦ä¹ çŠ¶å†µå¼•å¯¼å­¦ç”Ÿå‘ä½ æé—®ï¼Œæˆ–æ˜¯ç»™ä»–ä¸€äº›é¢˜ç›®ç»ƒä¹ ã€‚
å­¦ç”Ÿæœ€æ–°ä¸€å¥è¯ï¼š''' + student_msg + '''\nå­¦ç”Ÿçš„å­¦ä¹ æƒ…å†µï¼š''' + stu_img_content
    return get_chat_r1(query)

# å›¾çš„æ„å»º
class State(TypedDict):
    messages: Annotated[list, add_messages]
    node_name: str

def GraphBuilder():
    graph_builder = StateGraph(State)

    def stu_img_agent(state: State):
        return {"messages": [AIMessage(content=stu_img(st.session_state.history_msg[student_id], student_id))], "node_name": "stu_img_agent"}

    def check_msg_agent(state: State):
        return {"messages": [AIMessage(content=check_msg(st.session_state.history_msg[student_id], user_message))], "node_name": "check_msg_agent"}

    def question_rewrite_agent(state: State):
        return {"messages": [AIMessage(content=question_rewrite(st.session_state.history_msg[student_id], user_message))], "node_name": "question_rewrite_agent"}
    
    def wrong_question_rewrite_agent(state: State):
        return {"messages": [AIMessage(content=worng_question_rewrite(st.session_state.history_msg[student_id], user_message, state["messages"][-1].content))],
                "node_name": "wrong_question_rewrite_agent"}

    def route_intent_agent(state: State):
        global rewrite_user_message
        rewrite_user_message = state["messages"][-1].content
        return {"messages": [AIMessage(content=route_intent(rewrite_user_message))], "node_name": "route_intent_agent"}

    def answer_agent(state: State):
        return {"messages": [AIMessage(content=answer(rewrite_user_message, stu_img_content))], 
                "node_name": "answer_agent"}

    def concept_answer_agent(state: State):
        return {"messages": [AIMessage(content=concept_answer(rewrite_user_message, stu_img_content))], 
                "node_name": "concept_answer_agent"}
    
    def daily_conversation_agent(state: State):
        return {"messages": [AIMessage(content=daily_conversation(rewrite_user_message, stu_img_content))], 
                "node_name": "daily_conversation_agent"}
    
    def add_node():
        graph_builder.add_node("stu_img_agent", stu_img_agent)
        graph_builder.add_node("check_msg_agent", check_msg_agent)
        graph_builder.add_node("question_rewrite_agent", question_rewrite_agent)
        graph_builder.add_node("wrong_question_rewrite_agent", wrong_question_rewrite_agent)
        graph_builder.add_node("route_intent_agent", route_intent_agent)
        graph_builder.add_node("answer_agent", answer_agent)
        graph_builder.add_node("concept_answer_agent", concept_answer_agent)
        graph_builder.add_node("daily_conversation_agent", daily_conversation_agent)

    add_node()

    graph_builder.add_edge(START, "stu_img_agent")
    graph_builder.add_edge("stu_img_agent", "check_msg_agent")

    # è·¯ç”± åˆ¤æ–­ ä¸Šä¸€æ­¥ æ˜¯å¦checkå‡ºé—®é¢˜
    def rewrite_router(state):
        messages = state["messages"]
        last_message = messages[-1]

        if "æ— é—®é¢˜" in last_message.content:
            return "question_rewrite_agent"
        return "wrong_question_rewrite_agent"
    
    graph_builder.add_conditional_edges(
        "check_msg_agent",
        rewrite_router, 
        {"question_rewrite_agent": "question_rewrite_agent", "wrong_question_rewrite_agent": "wrong_question_rewrite_agent"},
    )
    graph_builder.add_edge("question_rewrite_agent", "route_intent_agent")
    graph_builder.add_edge("wrong_question_rewrite_agent", END)

    def router(state):
        messages = state["messages"]
        last_message = messages[-1]

        if "æ¦‚å¿µæ€§é—®é¢˜" in last_message.content:
            return "concept_answer_agent"
        elif "æ—¥å¸¸å¯¹è¯" in last_message.content:
            return "daily_conversation_agent"
        return "answer_agent"

    graph_builder.add_conditional_edges(
        "route_intent_agent",
        router,
        # {"continue": "chart_generator", "call_tool": "call_tool", END: END},
        {"concept_answer_agent": "concept_answer_agent", "daily_conversation_agent": "daily_conversation_agent", "answer_agent": "answer_agent"},
    )

    graph_builder.add_edge("concept_answer_agent",END)
    graph_builder.add_edge("daily_conversation_agent",END)
    graph_builder.add_edge("answer_agent",END)

    # è®°å¿†
    from langgraph.checkpoint.memory import MemorySaver
    memory = MemorySaver()
    graph = graph_builder.compile(
        checkpointer=memory
    )

    def draw_graph():
        from IPython.display import Image, display
        img_data = graph.get_graph().draw_mermaid_png()
        with open("output.png", "wb") as f:
            f.write(img_data)
        display(Image(img_data))
    # draw_graph()
    
    return graph

def get_config():
    if student_id == 'A':
        return configA
    elif student_id == 'B':
        return configB
    return config

def RetrieverBuilder(embedding_model_path: str, index_path: str):
    retriever_config = DenseRetrieverConfig(
        model_name_or_path=embedding_model_path,
        dim=1024,
        index_path= index_path
    )
    embedding_generator = FlagModelEmbedding(embedding_model_path)
    retriever = DenseRetriever(retriever_config, embedding_generator)
    retriever.load_index(index_path)
    return retriever

if __name__ == "__main__":
    graph = GraphBuilder() 
    embedding_model_path = r"D:/Python/models/bge-large-zh-v1.5"  # éšä¾¿å†™ä¸€ä¸ªå°±å¯ä»¥
    index_path = r'D:/code/agent_demo/dense_cache'
    qa_index_path = r'D:/code/agent_demo/qa_dense_cache'
    
    retriever = RetrieverBuilder(embedding_model_path, index_path)
    qa_retriever = RetrieverBuilder(embedding_model_path, qa_index_path)
    

    import streamlit as st
    
    student_id = ""
    # å†å²è®°å½• å­¦ç”Ÿå¯¹è¯ è‡ªåŠ¨è®°å½•Â·
    user_message = ""
    # æ”¹å†™åçš„é—®é¢˜
    rewrite_user_message = ""
    # å­¦ç”Ÿç”»åƒ
    stu_img_content = ""

    st.title('ğŸ¤– AIè€å¸ˆ')
    col1, col2 = st.columns([3, 1])
    
    # è®¾ç½®å­¦ç”ŸIDé€‰é¡¹
    student_id = st.selectbox('é€‰æ‹©å­¦ç”ŸID', ['A', 'B'])
    # TODO æ¨¡å‹é€‰æ‹©
    # model_name = st.selectbox('é€‰æ‹©æ¨¡å‹', ['DeepSeek-R1', 'DeepSeek-V3'])


    # åˆå§‹åŒ–èŠå¤©è®°å½•
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "history_msg" not in st.session_state:
        st.session_state.history_msg = {"A": "", "B": ""}

    # å±•ç¤ºèŠå¤©è®°å½•
    for message in st.session_state.messages:
        if message['student_id'] == student_id:
            if message["role"] == "user":
                with st.chat_message(message["role"], avatar='â˜ºï¸'):
                    st.markdown(message["content"])
            else:
                with st.chat_message(message["role"], avatar='ğŸ¤–'):
                    st.markdown(message["content"])


    # ç”¨äºç”¨æˆ·è¾“å…¥
    if user_message := st.chat_input('è¾“å…¥ä½ çš„é—®é¢˜...'):
        with st.chat_message('user', avatar='â˜ºï¸'):
            st.markdown(user_message)

        st.session_state.messages.append({'student_id': student_id, 'role': 'user', 'content': user_message})

        events = graph.stream(
            {
                "messages": [
                    HumanMessage(content=user_message)
                ],
                "node_name": "__start__",
            },
            get_config(),
            stream_mode="values"
        )
        
        with st.chat_message('assistant', avatar='ğŸ¤–'):
            for event in events:
                if "messages" in event:
                    with st.status(event["node_name"] + "...", expanded=True) as status:
                        if event["node_name"] == "answer_agent" or event["node_name"] == "concept_answer_agent" or event["node_name"] == "daily_conversation_agent":
                            st.markdown(event["messages"][-1].content)
                            status.update(
                                label=event["node_name"], state="complete", expanded=True
                            )
                        else:
                            st.markdown(event["node_name"])
                            status.update(
                                label=event["messages"][-1].content, state="complete", expanded=False
                            )
        
        st.session_state.messages.append({'student_id': student_id, 'role': 'assistant', 'content': event["messages"][-1].content})
        st.session_state.history_msg[student_id] = st.session_state.history_msg[student_id] + "å­¦ç”Ÿï¼š" + user_message + "\n"
        st.session_state.history_msg[student_id] = st.session_state.history_msg[student_id] + "æ•™å¸ˆï¼š" + event["messages"][-1].content + "\n"